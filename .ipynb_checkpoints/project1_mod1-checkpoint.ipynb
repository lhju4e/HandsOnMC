{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터전처리과정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#전체 데이터 셋에서 영화 관련 설문만 뽑아옴.\n",
    "#lable : 성별 // female : 0 male : 1// input : 영화 관련 설문 // \n",
    "#train 7 : test 3\n",
    "\n",
    "\n",
    "import os\n",
    "import tarfile \n",
    "from six.moves import urllib\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "ori_data = pd.read_csv(\"movie_preferences.csv\")\n",
    "data = ori_data\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns',150)\n",
    "plt.style.use('bmh')\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna(subset=[\"Gender\"], axis = 0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HanSung\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "gender_bi = data[\"Gender\"]\n",
    "gender_bi_encoded, gender_cate = gender_bi.factorize()\n",
    "#print(gender_bi_encoded) ##np.transpose해보기 -> 똑같음\n",
    "data[\"Gender\"] = gender_bi_encoded.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1004 entries, 0 to 1009\n",
      "Data columns (total 12 columns):\n",
      "Horror                 1002 non-null float64\n",
      "Thriller               1003 non-null float64\n",
      "Comedy                 1001 non-null float64\n",
      "Romantic               1001 non-null float64\n",
      "Sci-fi                 1002 non-null float64\n",
      "War                    1002 non-null float64\n",
      "Fantasy/Fairy tales    1001 non-null float64\n",
      "Animated               1002 non-null float64\n",
      "Documentary            996 non-null float64\n",
      "Western                1000 non-null float64\n",
      "Action                 1002 non-null float64\n",
      "Gender                 1004 non-null int64\n",
      "dtypes: float64(11), int64(1)\n",
      "memory usage: 102.0 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HanSung\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\utils\\deprecation.py:58: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#total_bedrooms 특성에는 값이 조금 누락되어있음. 이것을 전처리해줘야함.\n",
    "#사이킷런의 imputer는 누락된 값을 특성의 중간값으로 대체함\n",
    "\n",
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "imputer = Imputer(strategy=\"median\")\n",
    "imputer.fit(data)\n",
    "X = imputer.transform(data)\n",
    "#위의 결과값은 넘파이 배열인데, 이것을 다시 판다스 프레임으로 되돌림.\n",
    "data = pd.DataFrame(X, columns=data.columns, index = list(data.index.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1004 entries, 0 to 1009\n",
      "Data columns (total 12 columns):\n",
      "Horror                 1004 non-null float64\n",
      "Thriller               1004 non-null float64\n",
      "Comedy                 1004 non-null float64\n",
      "Romantic               1004 non-null float64\n",
      "Sci-fi                 1004 non-null float64\n",
      "War                    1004 non-null float64\n",
      "Fantasy/Fairy tales    1004 non-null float64\n",
      "Animated               1004 non-null float64\n",
      "Documentary            1004 non-null float64\n",
      "Western                1004 non-null float64\n",
      "Action                 1004 non-null float64\n",
      "Gender                 1004 non-null float64\n",
      "dtypes: float64(12)\n",
      "memory usage: 102.0 KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.info()\n",
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HanSung\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:13: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  del sys.path[0]\n",
      "C:\\Users\\HanSung\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:14: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#테스트 세트 만들기 train 7 : test 3\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=42)\n",
    "#for train_index, test_index in split.split(data, data_label):\n",
    "#    strat_train_set, strat_test_set = data[train_index], data[test_index]\n",
    "#    label_train_set, label_test_set = label[train_index], label[test_index]\n",
    "    \n",
    "    \n",
    "for train_index, test_index in split.split(data, data[\"Gender\"]):\n",
    "    train_set = data.loc[train_index]\n",
    "    test_set = data.loc[test_index]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HanSung\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:11: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\HanSung\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:14: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_set = train_set.dropna(subset=[\"Gender\"], axis = 0 ) #왜인지 모르겠는데 자꾸 nan이 떠서 지워줌\n",
    "test_set = test_set.dropna(subset=[\"Gender\"], axis = 0)\n",
    "\n",
    "train_label = train_set[\"Gender\"].copy()\n",
    "train = train_set.drop(\"Gender\", axis=1)\n",
    "\n",
    "test_label = test_set[\"Gender\"].copy()\n",
    "test = test_set.drop(\"Gender\", axis=1)\n",
    "\n",
    "train_label = train_label.as_matrix(columns = None)\n",
    "train_label = train_label.reshape(-1, 1)\n",
    "\n",
    "test_label = test_label.as_matrix(columns = None)\n",
    "test_label = test_label.reshape(-1, 1)\n",
    "\n",
    "#코쎄라 코드 보고하는데, 형식 맞춰주기\n",
    "train = np.transpose(train)\n",
    "train_label = np.transpose(train_label)\n",
    "\n",
    "test = np.transpose(test)\n",
    "test_label = np.transpose(test_label)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 트레이닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "\n",
    "%matplotlib inline\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11, 698)\n",
      "(1, 698)\n",
      "(11, 300)\n",
      "(1, 300)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "print(train_label.shape)\n",
    "\n",
    "print(test.shape)\n",
    "print(test_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_prob = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델 생성\n",
    "\n",
    "X = tf.placeholder(shape=[11, None], dtype=tf.float32)\n",
    "Y = tf.placeholder(shape=[1, None], dtype=tf.float32)\n",
    "\n",
    "tf.set_random_seed(1)  \n",
    "\n",
    "#20 - 8 -> 30 - 15 (1000번 반복에 dropout0.6 => 82%)\n",
    "#50 - 25 (1000번 반복에 dropout 0.5 => 81.3%)\n",
    "#with tf.variable_scope(\"model\", reuse=True):\n",
    "W1 = tf.get_variable(\"W1\", [30, 11], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "b1 = tf.get_variable(\"b1\", [30, 1],  initializer = tf.zeros_initializer())\n",
    "W2 = tf.get_variable(\"W2\", [15, 30],  initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "b2 = tf.get_variable(\"b2\", [15, 1],  initializer = tf.zeros_initializer())\n",
    "W3 = tf.get_variable(\"W3\", [1, 15],  initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "b3 = tf.get_variable(\"b3\", [1 ,1],  initializer = tf.zeros_initializer())\n",
    "\n",
    "Z1 = tf.add(tf.matmul(W1, X), b1)                       \n",
    "A1 = tf.nn.relu(Z1)\n",
    "A1 = tf.nn.dropout(A1, keep_prob)\n",
    "Z2 = tf.add(tf.matmul(W2, A1), b2)                      \n",
    "A2 = tf.nn.relu(Z2) \n",
    "A2 = tf.nn.dropout(A2, keep_prob)\n",
    "Z3 = tf.add(tf.matmul(W3, A2), b3)                      \n",
    "A3 = tf.nn.sigmoid(Z3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#하이퍼파라미터 셋팅\n",
    "\n",
    "learning_rate = 0.01\n",
    "training_epochs = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "Tensor(\"Sigmoid:0\", shape=(1, ?), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(type(train_label))\n",
    "print(str(A3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#비용계산 - 최적화 함수 Adam optimizer를 이용\n",
    "\n",
    "cross_entropy = tf.nn.sigmoid_cross_entropy_with_logits(labels=Y, logits=Z3)\n",
    "\n",
    "cost = tf.reduce_mean(cross_entropy)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "predicted = A3\n",
    "correct_pred = tf.equal(tf.round(predicted), Y)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy -----\n",
      "Step:     0\tLoss: 0.985\tAcc: 45.85%\n",
      "Step:   100\tLoss: 0.417\tAcc: 82.52%\n",
      "Step:   200\tLoss: 0.377\tAcc: 83.52%\n",
      "Step:   300\tLoss: 0.372\tAcc: 83.67%\n",
      "Step:   400\tLoss: 0.355\tAcc: 85.39%\n",
      "Step:   500\tLoss: 0.330\tAcc: 84.38%\n",
      "Step:   600\tLoss: 0.347\tAcc: 84.24%\n",
      "Step:   700\tLoss: 0.338\tAcc: 84.53%\n",
      "Step:   800\tLoss: 0.346\tAcc: 84.81%\n",
      "Step:   900\tLoss: 0.338\tAcc: 85.39%\n",
      "Step:  1000\tLoss: 0.353\tAcc: 84.53%\n",
      "-------\n",
      "Test Accuracy: 0.82\n"
     ]
    }
   ],
   "source": [
    "#모델 돌림\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(\"Train Accuracy -----\")\n",
    "    for step in range(training_epochs + 1):\n",
    "        sess.run(optimizer, feed_dict={X: train, Y: train_label,  keep_prob:0.6})\n",
    "        loss, _, acc = sess.run([cost, optimizer, accuracy], feed_dict={\n",
    "                                 X: train, Y: train_label, keep_prob:0.6})\n",
    "        if step % 100 == 0:\n",
    "            print(\"Step: {:5}\\tLoss: {:.3f}\\tAcc: {:.2%}\".format(\n",
    "                step, loss, acc))\n",
    "            \n",
    "    print('-------\\nTest Accuracy:', accuracy.eval({X: test, Y: test_label, keep_prob:1.0}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#반복 횟수를 100 -> 1000으로 늘리면 train accuracy가 높아지기는 하지만(86%), test accuracy는 거의 비슷했다(80%).\n",
    "#과적합을 고치기 위해 dropout을 도입해서 사용하였으나, 효과가 거의 없었다. 네트워크의 크기가 작아서 별 의미가 없는 듯 하다.\n",
    "#그래서 네트워크 크기를 조금씩 늘려보면서 정확도를 보았는데 30-15을 하고 dropout을 설정하는 것이 제일 좋았다..\n",
    "#그래봤자 조금올랐지만 ㅜㅜ 아마 데이터 세트가 너무 작아서 그런 것 같다.\n",
    "#정규화를 해볼까 생각했지만, 입력 데이터가 이미 어느정도 정규화가 되어 있는 것 같아서(1-5) 하지 않았다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Horror  Thriller  Comedy  Romantic  Sci-fi  War  Fantasy/Fairy tales  \\\n",
      "0     4.0       2.0     5.0       4.0     4.0  1.0                  5.0   \n",
      "1     2.0       2.0     4.0       3.0     4.0  1.0                  3.0   \n",
      "2     3.0       4.0     4.0       2.0     4.0  2.0                  5.0   \n",
      "\n",
      "   Animated  Documentary  Western  Action  Gender  \n",
      "0       5.0          3.0      1.0     2.0     0.0  \n",
      "1       5.0          4.0      1.0     4.0     0.0  \n",
      "2       5.0          2.0      2.0     1.0     0.0  \n"
     ]
    }
   ],
   "source": [
    "#새로운 세트 하나 만들기\n",
    "\n",
    "print(data.head(3))\n",
    "\n",
    "new_test = np.array([1.0, 5.0, 4.0, 1.0, 3.0, 3.0, 5.0, 5.0, 2.0, 1.0, 5.0])\n",
    "new_test_label = np.array([0])\n",
    "\n",
    "new_test2 = np.array([1.0, 2.0, 5.0, 5.0, 2.0, 2.0, 5.0, 5.0, 2.0, 1.0, 2.0])\n",
    "new_test_label2 = np.array([0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_test = new_test.reshape(-1, 1)\n",
    "#new_test = np.transpose(new_test)\n",
    "new_test_label = new_test_label.reshape(-1, 1)\n",
    "#new_test_label = np.transpose(new_test_label)\n",
    "new_test2 = new_test.reshape(-1, 1)\n",
    "#new_test = np.transpose(new_test)\n",
    "new_test_label2 = new_test_label.reshape(-1, 1)\n",
    "#new_test_label = np.transpose(new_test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11, 698)\n",
      "(11, 1)\n",
      "(1, 1)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "print(new_test.shape)\n",
    "print(new_test_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------\n",
      "Test: 0.0\n",
      "-------\n",
      "Test: 0.0\n",
      "-------\n",
      "Test: 0.82\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for step in range(training_epochs + 1):\n",
    "        sess.run(optimizer, feed_dict={X: train, Y: train_label,  keep_prob:0.6})\n",
    "        loss, _, acc = sess.run([cost, optimizer, accuracy], feed_dict={\n",
    "                                 X: train, Y: train_label, keep_prob:0.6})\n",
    "    print('-------\\nTest:', accuracy.eval({X: new_test, Y: new_test_label, keep_prob:1.0}))\n",
    "    print('-------\\nTest:', accuracy.eval({X: new_test2, Y: new_test_label2, keep_prob:1.0}))\n",
    "    print('-------\\nTest:', accuracy.eval({X: test, Y: test_label, keep_prob:1.0}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

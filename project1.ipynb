{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터전처리과정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#전체 데이터 셋에서 영화 관련 설문만 뽑아옴.\n",
    "#lable : 성별 // female : 0 male : 1// input : 영화 관련 설문 // \n",
    "#train 7 : test 3\n",
    "\n",
    "\n",
    "import os\n",
    "import tarfile \n",
    "from six.moves import urllib\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "ori_data = pd.read_csv(\"movie_preferences.csv\")\n",
    "data = ori_data\n",
    "\n",
    "\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns',150)\n",
    "plt.style.use('bmh')\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna(subset=[\"Gender\"], axis = 0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HanSung\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "gender_bi = data[\"Gender\"]\n",
    "gender_bi_encoded, gender_cate = gender_bi.factorize()\n",
    "#print(gender_bi_encoded) ##np.transpose해보기 -> 똑같음\n",
    "data[\"Gender\"] = gender_bi_encoded.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1004 entries, 0 to 1009\n",
      "Data columns (total 12 columns):\n",
      "Horror                 1002 non-null float64\n",
      "Thriller               1003 non-null float64\n",
      "Comedy                 1001 non-null float64\n",
      "Romantic               1001 non-null float64\n",
      "Sci-fi                 1002 non-null float64\n",
      "War                    1002 non-null float64\n",
      "Fantasy/Fairy tales    1001 non-null float64\n",
      "Animated               1002 non-null float64\n",
      "Documentary            996 non-null float64\n",
      "Western                1000 non-null float64\n",
      "Action                 1002 non-null float64\n",
      "Gender                 1004 non-null int64\n",
      "dtypes: float64(11), int64(1)\n",
      "memory usage: 102.0 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HanSung\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\utils\\deprecation.py:58: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#total_bedrooms 특성에는 값이 조금 누락되어있음. 이것을 전처리해줘야함.\n",
    "#사이킷런의 imputer는 누락된 값을 특성의 중간값으로 대체함\n",
    "\n",
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "imputer = Imputer(strategy=\"median\")\n",
    "imputer.fit(data)\n",
    "X = imputer.transform(data)\n",
    "#위의 결과값은 넘파이 배열인데, 이것을 다시 판다스 프레임으로 되돌림.\n",
    "data = pd.DataFrame(X, columns=data.columns, index = list(data.index.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1004 entries, 0 to 1009\n",
      "Data columns (total 12 columns):\n",
      "Horror                 1004 non-null float64\n",
      "Thriller               1004 non-null float64\n",
      "Comedy                 1004 non-null float64\n",
      "Romantic               1004 non-null float64\n",
      "Sci-fi                 1004 non-null float64\n",
      "War                    1004 non-null float64\n",
      "Fantasy/Fairy tales    1004 non-null float64\n",
      "Animated               1004 non-null float64\n",
      "Documentary            1004 non-null float64\n",
      "Western                1004 non-null float64\n",
      "Action                 1004 non-null float64\n",
      "Gender                 1004 non-null float64\n",
      "dtypes: float64(12)\n",
      "memory usage: 102.0 KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.info()\n",
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HanSung\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:13: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  del sys.path[0]\n",
      "C:\\Users\\HanSung\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:14: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#테스트 세트 만들기 train 7 : test 3\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=42)\n",
    "#for train_index, test_index in split.split(data, data_label):\n",
    "#    strat_train_set, strat_test_set = data[train_index], data[test_index]\n",
    "#    label_train_set, label_test_set = label[train_index], label[test_index]\n",
    "    \n",
    "    \n",
    "for train_index, test_index in split.split(data, data[\"Gender\"]):\n",
    "    train_set = data.loc[train_index]\n",
    "    test_set = data.loc[test_index]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HanSung\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:11: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\HanSung\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:14: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_set = train_set.dropna(subset=[\"Gender\"], axis = 0 ) #왜인지 모르겠는데 자꾸 nan이 떠서 지워줌\n",
    "test_set = test_set.dropna(subset=[\"Gender\"], axis = 0)\n",
    "\n",
    "train_label = train_set[\"Gender\"].copy()\n",
    "train = train_set.drop(\"Gender\", axis=1)\n",
    "\n",
    "test_label = test_set[\"Gender\"].copy()\n",
    "test = test_set.drop(\"Gender\", axis=1)\n",
    "\n",
    "train_label = train_label.as_matrix(columns = None)\n",
    "train_label = train_label.reshape(-1, 1)\n",
    "\n",
    "test_label = test_label.as_matrix(columns = None)\n",
    "test_label = test_label.reshape(-1, 1)\n",
    "\n",
    "#코쎄라 코드 보고하는데, 형식 맞춰주기\n",
    "train = np.transpose(train)\n",
    "train_label = np.transpose(train_label)\n",
    "\n",
    "test = np.transpose(test)\n",
    "test_label = np.transpose(test_label)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 트레이닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "\n",
    "%matplotlib inline\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11, 698)\n",
      "(1, 698)\n",
      "(11, 300)\n",
      "(1, 300)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "print(train_label.shape)\n",
    "\n",
    "print(test.shape)\n",
    "print(test_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "get_variable() got an unexpected keyword argument 'reuse'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-81f6545e1f33>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_random_seed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mW1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_variable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"W1\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m11\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreuse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitializer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxavier_initializer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mb1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_variable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"b1\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0mreuse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitializer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros_initializer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mW2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_variable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"W2\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0mreuse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitializer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxavier_initializer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: get_variable() got an unexpected keyword argument 'reuse'"
     ]
    }
   ],
   "source": [
    "#모델 생성\n",
    "\n",
    "X = tf.placeholder(shape=[11, None], dtype=tf.float32)\n",
    "Y = tf.placeholder(shape=[1, None], dtype=tf.float32)\n",
    "\n",
    "tf.set_random_seed(1)  \n",
    "\n",
    "W1 = tf.get_variable(\"W1\", [20, 11], reuse = True, initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "b1 = tf.get_variable(\"b1\", [20, 1],  reuse = True, initializer = tf.zeros_initializer())\n",
    "W2 = tf.get_variable(\"W2\", [8, 20],  reuse = True, initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "b2 = tf.get_variable(\"b2\", [8, 1],  reuse = True, initializer = tf.zeros_initializer())\n",
    "W3 = tf.get_variable(\"W3\", [1, 8],  reuse = True, initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "b3 = tf.get_variable(\"b3\", [1 ,1],  reuse = True, initializer = tf.zeros_initializer())\n",
    "\n",
    "Z1 = tf.add(tf.matmul(W1, X), b1)                       # Z1 = np.dot(W1, X) + b1\n",
    "A1 = tf.nn.relu(Z1)                                     # A1 = relu(Z1)\n",
    "Z2 = tf.add(tf.matmul(W2, A1), b2)                      # Z2 = np.dot(W2, a1) + b2\n",
    "A2 = tf.nn.relu(Z2)                                     # A2 = relu(Z2)\n",
    "Z3 = tf.add(tf.matmul(W3, A2), b3)                      # Z3 = np.dot(W3,Z2) + b3\n",
    "A3 = tf.nn.sigmoid(Z3)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#하이퍼파라미터\n",
    "\n",
    "learning_rate = 0.01\n",
    "training_epochs = 100\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "Tensor(\"Sigmoid:0\", shape=(1, ?), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(type(train_label))\n",
    "print(str(A3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#비용계산 - 최적화 함수 gradient descent 이용\n",
    "\n",
    "cross_entropy = tf.nn.sigmoid_cross_entropy_with_logits(labels=Y, logits=Z3)\n",
    "###여기 logits에 A3넣어야 하나 Z3 넣어야 하나 헷갈림\n",
    "\n",
    "cost = tf.reduce_mean(cross_entropy)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "predicted = A3\n",
    "correct_pred = tf.equal(tf.round(predicted), Y)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy -----\n",
      "Step:     0\tLoss: 1.040\tAcc: 40.11%\n",
      "Step:     5\tLoss: 0.591\tAcc: 71.20%\n",
      "Step:    10\tLoss: 0.485\tAcc: 76.65%\n",
      "Step:    15\tLoss: 0.441\tAcc: 78.37%\n",
      "Step:    20\tLoss: 0.416\tAcc: 79.80%\n",
      "Step:    25\tLoss: 0.403\tAcc: 81.38%\n",
      "Step:    30\tLoss: 0.396\tAcc: 81.23%\n",
      "Step:    35\tLoss: 0.393\tAcc: 80.66%\n",
      "Step:    40\tLoss: 0.391\tAcc: 80.80%\n",
      "Step:    45\tLoss: 0.388\tAcc: 81.23%\n",
      "Step:    50\tLoss: 0.386\tAcc: 81.23%\n",
      "Step:    55\tLoss: 0.384\tAcc: 81.09%\n",
      "Step:    60\tLoss: 0.382\tAcc: 80.95%\n",
      "Step:    65\tLoss: 0.380\tAcc: 81.66%\n",
      "Step:    70\tLoss: 0.378\tAcc: 81.81%\n",
      "Step:    75\tLoss: 0.376\tAcc: 82.38%\n",
      "Step:    80\tLoss: 0.374\tAcc: 82.52%\n",
      "Step:    85\tLoss: 0.371\tAcc: 81.95%\n",
      "Step:    90\tLoss: 0.369\tAcc: 82.09%\n",
      "Step:    95\tLoss: 0.366\tAcc: 82.38%\n",
      "Step:   100\tLoss: 0.364\tAcc: 82.66%\n",
      "-------\n",
      "Test Accuracy: 0.8066667\n"
     ]
    }
   ],
   "source": [
    "#모델 돌림\n",
    "\n",
    "with tf.Session() as sess.as_default():\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(\"Train Accuracy -----\")\n",
    "    for step in range(training_epochs + 1):\n",
    "        sess.run(optimizer, feed_dict={X: train, Y: train_label})\n",
    "        loss, _, acc = sess.run([cost, optimizer, accuracy], feed_dict={\n",
    "                                 X: train, Y: train_label})\n",
    "        if step % 5 == 0:\n",
    "            print(\"Step: {:5}\\tLoss: {:.3f}\\tAcc: {:.2%}\".format(\n",
    "                step, loss, acc))\n",
    "            \n",
    "    print('-------\\nTest Accuracy:', accuracy.eval({X: test, Y: test_label}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#새로운 세트 하나 만들기\n",
    "\n",
    "data.head(3)\n",
    "#내 데이터....\n",
    "\n",
    "new_test = [1.0, 5.0, 4.0, 1.0, 3.0, 3.0, 5.0, 5.0, 2.0, 1.0, 5.0]\n",
    "new_test_label = [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head(11)\n",
    "\n",
    "new_test = np.transpose(new_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot evaluate tensor using `eval()`: No default session is registered. Use `with sess.as_default()` or pass an explicit session to `eval(session=sess)`",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-8d929ca8b734>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'-------\\nTest Accuracy:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnew_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnew_test_label\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36meval\u001b[1;34m(self, feed_dict, session)\u001b[0m\n\u001b[0;32m    678\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    679\u001b[0m     \"\"\"\n\u001b[1;32m--> 680\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_eval_using_default_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    681\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    682\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_eval_using_default_session\u001b[1;34m(tensors, feed_dict, graph, session)\u001b[0m\n\u001b[0;32m   4935\u001b[0m     \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_default_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4936\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msession\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4937\u001b[1;33m       raise ValueError(\"Cannot evaluate tensor using `eval()`: No default \"\n\u001b[0m\u001b[0;32m   4938\u001b[0m                        \u001b[1;34m\"session is registered. Use `with \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4939\u001b[0m                        \u001b[1;34m\"sess.as_default()` or pass an explicit session to \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot evaluate tensor using `eval()`: No default session is registered. Use `with sess.as_default()` or pass an explicit session to `eval(session=sess)`"
     ]
    }
   ],
   "source": [
    "print('-------\\nTest Accuracy:', accuracy.eval({X: new_test, Y: new_test_label}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
